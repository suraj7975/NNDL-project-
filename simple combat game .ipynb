{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VbF6MUse5XVy"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"OF1pFpci0zpv","outputId":"99f0fe3f-2ee5-4f2d-8c1f-05702ca7cf1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Simple Combat Game with RNN predictor\n","\n","Pretrain model on synthetic opponents for a better start? (y/n): y\n","[Pretrain] Epoch 1/6  loss=1.0578\n","[Pretrain] Epoch 2/6  loss=0.9563\n","[Pretrain] Epoch 3/6  loss=0.8755\n","[Pretrain] Epoch 4/6  loss=0.8342\n","[Pretrain] Epoch 5/6  loss=0.8179\n","[Pretrain] Epoch 6/6  loss=0.7874\n","\n","Choose opponent mode:\n","1) human (you play)\n","2) aggressive\n","3) defensive\n","4) random\n","5) patterned\n","6) mixed\n","Select 1-6: 1\n","\n","--- Simple Combat Game (Attack, Block, Dodge) ---\n","Type: 'a' for Attack, 'b' for Block, 'd' for Dodge, 'q' to quit.\n","Bot predicts your next move and chooses a counter.\n","\n","\n","Last moves: ['Dodge', 'Dodge', 'Dodge', 'Dodge', 'Attack', 'Dodge']\n","Your move (a/b/d or q): a\n","Bot predicted you would do: Dodge  (conf 0.51)\n","Bot move: Attack | Your move: Attack -> Tie\n","Rounds: 1 | Pred Acc: 0.000 | Bot wins: 0 | Player wins: 0 | Ties: 1 | Last loss: 1.3675\n","\n","Last moves: ['Dodge', 'Dodge', 'Dodge', 'Attack', 'Dodge', 'Attack']\n","Your move (a/b/d or q): d\n","Bot predicted you would do: Dodge  (conf 0.38)\n","Bot move: Attack | Your move: Dodge -> Bot wins\n","Rounds: 2 | Pred Acc: 0.500 | Bot wins: 1 | Player wins: 0 | Ties: 1 | Last loss: 0.9648\n","\n","Last moves: ['Dodge', 'Dodge', 'Attack', 'Dodge', 'Attack', 'Dodge']\n"]}],"source":["# combat_rnn_game.py\n","# Requirements: torch, numpy\n","# Run: python combat_rnn_game.py\n","\n","import random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from collections import deque, Counter\n","import os\n","import json\n","import time\n","\n","# ---------------- Config ----------------\n","SEQ_LEN = 6            # how many previous player moves to feed the RNN\n","HIDDEN_SIZE = 64\n","NUM_LAYERS = 1\n","LR = 0.01\n","PRETRAIN_SAMPLES = 1500  # synthetic pretrain size\n","ONLINE_LR = 0.005        # smaller LR for online updates\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","MODEL_PATH = \"combat_rnn_model.pt\"\n","MOVES = ['Attack', 'Block', 'Dodge']\n","move_to_idx = {m: i for i, m in enumerate(MOVES)}\n","idx_to_move = {i: m for m, i in move_to_idx.items()}\n","\n","\n","# Utility: which move beats which\n","# We'll define: Attack beats Dodge (attack hits dodger),\n","# Block beats Attack (block defends), Dodge beats Block (dodge around block).\n","WIN_MAP = {\n","    'Attack': 'Dodge',   # Attack beats Dodge\n","    'Block':  'Attack',  # Block beats Attack\n","    'Dodge':  'Block'    # Dodge beats Block\n","}\n","# To choose bot move that counters predicted player move, pick the move that beats the player's predicted move:\n","# e.g. if player predicted to do Attack -> bot should do Block (because Block beats Attack)\n","def counter_move(pred_player_move):\n","    # find move m such that WIN_MAP[m] == pred_player_move\n","    for m, beats in WIN_MAP.items():\n","        if beats == pred_player_move:\n","            return m\n","    return random.choice(MOVES)\n","\n","\n","# ---------------- Synthetic opponent generators ----------------\n","def aggressive_player():\n","    # favors Attack heavily, but with occasional switches\n","    while True:\n","        r = random.random()\n","        if r < 0.7:\n","            yield 'Attack'\n","        elif r < 0.85:\n","            yield 'Dodge'\n","        else:\n","            yield 'Block'\n","\n","def defensive_player():\n","    # favors Block\n","    while True:\n","        r = random.random()\n","        if r < 0.7:\n","            yield 'Block'\n","        elif r < 0.85:\n","            yield 'Attack'\n","        else:\n","            yield 'Dodge'\n","\n","def random_player():\n","    while True:\n","        yield random.choice(MOVES)\n","\n","def patterned_player(pattern=['Attack', 'Attack', 'Block', 'Dodge']):\n","    i = 0\n","    while True:\n","        yield pattern[i % len(pattern)]\n","        i += 1\n","\n","def mixed_player():\n","    # switch strategy every 50 moves\n","    gens = [aggressive_player(), defensive_player(), patterned_player(), random_player()]\n","    i = 0\n","    gen = random.choice(gens)\n","    while True:\n","        if i % 50 == 0:\n","            gen = random.choice(gens)\n","        yield next(gen)\n","        i += 1\n","\n","SYNTH_OPS = {\n","    'aggressive': aggressive_player,\n","    'defensive': defensive_player,\n","    'random': random_player,\n","    'patterned': lambda: patterned_player(['Attack','Dodge','Block']),\n","    'mixed': mixed_player\n","}\n","\n","# ---------------- Dataset helpers ----------------\n","def moves_to_onehot(seq):\n","    # seq: list of move strings length SEQ_LEN\n","    arr = np.zeros((len(seq), len(MOVES)), dtype=np.float32)\n","    for i, m in enumerate(seq):\n","        idx = move_to_idx[m]\n","        arr[i, idx] = 1.0\n","    return arr  # shape (seq_len, 3)\n","\n","def seq_to_tensor(seq):\n","    # return shape (1, SEQ_LEN, 3) float tensor\n","    return torch.tensor(moves_to_onehot(seq), dtype=torch.float32, device=DEVICE).unsqueeze(0)\n","\n","\n","# ---------------- Model definition ----------------\n","class GRUPredictor(nn.Module):\n","    def __init__(self, input_size=3, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=3):\n","        super().__init__()\n","        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        # x: (batch, seq_len, input_size)\n","        out, h = self.gru(x)           # out: (batch, seq_len, hidden)\n","        last = out[:, -1, :]           # (batch, hidden)\n","        logits = self.fc(last)         # (batch, output_size)\n","        return logits\n","\n","# ---------------- Train on synthetic data for a warm start ----------------\n","def generate_pretrain_data(gen_fn, n_samples=1000):\n","    gen = gen_fn()\n","    history = deque([next(gen) for _ in range(SEQ_LEN)], maxlen=SEQ_LEN)\n","    X = []\n","    Y = []\n","    for _ in range(n_samples):\n","        X.append(list(history))\n","        nxt = next(gen)\n","        Y.append(move_to_idx[nxt])\n","        history.append(nxt)\n","    return X, Y\n","\n","def pretrain_model(model, epochs=6, batch_size=64):\n","    model.train()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","    loss_fn = nn.CrossEntropyLoss()\n","    # build mixed synthetic data\n","    X_all, Y_all = [], []\n","    per_gen = PRETRAIN_SAMPLES // len(SYNTH_OPS)\n","    for name, gen in SYNTH_OPS.items():\n","        X, Y = generate_pretrain_data(gen, per_gen)\n","        X_all.extend(X)\n","        Y_all.extend(Y)\n","    # shuffle\n","    perm = list(range(len(Y_all)))\n","    random.shuffle(perm)\n","    X_all = [X_all[i] for i in perm]\n","    Y_all = [Y_all[i] for i in perm]\n","    # training loop\n","    for ep in range(epochs):\n","        total_loss = 0.0\n","        for i in range(0, len(Y_all), batch_size):\n","            xb = X_all[i:i+batch_size]\n","            yb = Y_all[i:i+batch_size]\n","            x_tensor = torch.stack([torch.tensor(moves_to_onehot(seq), device=DEVICE) for seq in xb], dim=0)\n","            y_tensor = torch.tensor(yb, dtype=torch.long, device=DEVICE)\n","            optimizer.zero_grad()\n","            logits = model(x_tensor)\n","            loss = loss_fn(logits, y_tensor)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item() * x_tensor.size(0)\n","        avg = total_loss / len(Y_all)\n","        print(f\"[Pretrain] Epoch {ep+1}/{epochs}  loss={avg:.4f}\")\n","    return model\n","\n","# ---------------- Online update (one step) ----------------\n","def online_update(model, optimizer, criterion, seq_history, true_move):\n","    model.train()\n","    x = seq_to_tensor(list(seq_history))  # (1, seq_len, 3)\n","    y = torch.tensor([move_to_idx[true_move]], dtype=torch.long, device=DEVICE)\n","    optimizer.zero_grad()\n","    logits = model(x)\n","    loss = criterion(logits, y)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","# ---------------- Save / Load helpers ----------------\n","def save_model(model, path=MODEL_PATH, meta=None):\n","    data = {\n","        'state_dict': model.state_dict(),\n","        'meta': meta or {}\n","    }\n","    torch.save(data, path)\n","    print(\"Saved model to\", path)\n","\n","def load_model(path=MODEL_PATH):\n","    if not os.path.exists(path):\n","        return None\n","    data = torch.load(path, map_location=DEVICE)\n","    model = GRUPredictor().to(DEVICE)\n","    model.load_state_dict(data['state_dict'])\n","    print(\"Loaded model from\", path)\n","    return model\n","\n","# ---------------- Gameplay ----------------\n","def play_game(model=None, opponent_mode='human'):\n","    # model: GRUPredictor instance (can be None -> random bot)\n","    # opponent_mode: if not 'human', uses synthetic generator for simulated human moves\n","    if model is None:\n","        model = GRUPredictor().to(DEVICE)\n","    model.eval()\n","    opt_online = torch.optim.SGD(model.parameters(), lr=ONLINE_LR)\n","    loss_fn = nn.CrossEntropyLoss()\n","\n","    # initialize history with random moves\n","    history = deque([random.choice(MOVES) for _ in range(SEQ_LEN)], maxlen=SEQ_LEN)\n","\n","    # stats\n","    total_rounds = 0\n","    correct_preds = 0\n","    bot_wins = 0\n","    player_wins = 0\n","    ties = 0\n","    pred_counts = Counter()\n","\n","    # if opponent_mode is synthetic, create generator\n","    opp_gen = None\n","    if opponent_mode != 'human':\n","        gen_fn = SYNTH_OPS.get(opponent_mode, random_player)\n","        opp_gen = gen_fn()\n","\n","    print(\"\\n--- Simple Combat Game (Attack, Block, Dodge) ---\")\n","    print(\"Type: 'a' for Attack, 'b' for Block, 'd' for Dodge, 'q' to quit.\")\n","    print(\"Bot predicts your next move and chooses a counter.\\n\")\n","\n","    try:\n","        while True:\n","            # Display last few moves\n","            print(\"\\nLast moves:\", list(history))\n","            # Model prediction\n","            x = seq_to_tensor(list(history))\n","            with torch.no_grad():\n","                logits = model(x)\n","                probs = F.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n","                pred_idx = int(logits.argmax(dim=1).item())\n","                pred_move = idx_to_move[pred_idx]\n","\n","            # Bot chooses counter\n","            bot_move = counter_move(pred_move)\n","\n","            # Ask for player move if human, otherwise sample from opp_gen\n","            if opponent_mode == 'human':\n","                ans = input(\"Your move (a/b/d or q): \").strip().lower()\n","                if ans == 'q':\n","                    break\n","                if ans not in ['a', 'b', 'd']:\n","                    print(\"Invalid. Use a/b/d or q.\")\n","                    continue\n","                player_move = {'a':'Attack','b':'Block','d':'Dodge'}[ans]\n","            else:\n","                player_move = next(opp_gen)\n","                print(f\"[Simulated player] {player_move}\")\n","\n","            # Evaluate result\n","            total_rounds += 1\n","            pred_counts[pred_move] += 1\n","            if pred_move == player_move:\n","                correct_preds += 1\n","            # Decide winner\n","            if bot_move == player_move:\n","                ties += 1\n","                outcome = \"Tie\"\n","            elif WIN_MAP[bot_move] == player_move:\n","                bot_wins += 1\n","                outcome = \"Bot wins\"\n","            elif WIN_MAP[player_move] == bot_move:\n","                player_wins += 1\n","                outcome = \"Player wins\"\n","            else:\n","                outcome = \"Undetermined\"\n","\n","            print(f\"Bot predicted you would do: {pred_move}  (conf {probs[pred_idx]:.2f})\")\n","            print(f\"Bot move: {bot_move} | Your move: {player_move} -> {outcome}\")\n","\n","            # Online learning: update model with the new observed sample (history -> true next)\n","            # Use one gradient step\n","            loss_val = online_update(model, opt_online, loss_fn, history, player_move)\n","\n","            # Update history (append player's move)\n","            history.append(player_move)\n","\n","            # Print stats\n","            acc = correct_preds / total_rounds if total_rounds else 0.0\n","            print(f\"Rounds: {total_rounds} | Pred Acc: {acc:.3f} | Bot wins: {bot_wins} | Player wins: {player_wins} | Ties: {ties} | Last loss: {loss_val:.4f}\")\n","\n","    except KeyboardInterrupt:\n","        print(\"\\nInterrupted by user.\")\n","\n","    # Summary\n","    print(\"\\n--- Game Summary ---\")\n","    print(\"Total rounds:\", total_rounds)\n","    print(\"Prediction accuracy:\", correct_preds, \"/\", total_rounds, f\"({(correct_preds/total_rounds if total_rounds else 0):.3f})\")\n","    print(\"Bot wins:\", bot_wins, \"Player wins:\", player_wins, \"Ties:\", ties)\n","    print(\"Prediction distribution (top 3):\", pred_counts.most_common(3))\n","\n","    return model\n","\n","# ---------------- CLI entrypoint ----------------\n","def main():\n","    print(\"Simple Combat Game with RNN predictor\\n\")\n","    # Offer to load existing model\n","    model = None\n","    if os.path.exists(MODEL_PATH):\n","        yn = input(f\"Load saved model from {MODEL_PATH}? (y/n): \").strip().lower()\n","        if yn == 'y':\n","            model = load_model(MODEL_PATH)\n","    if model is None:\n","        model = GRUPredictor().to(DEVICE)\n","        # Offer to pretrain on synthetic opponents for a warm start\n","        yn = input(\"Pretrain model on synthetic opponents for a better start? (y/n): \").strip().lower()\n","        if yn == 'y':\n","            pretrain_model(model, epochs=6)\n","\n","    # Choose playing mode\n","    print(\"\\nChoose opponent mode:\")\n","    print(\"1) human (you play)\")\n","    print(\"2) aggressive\")\n","    print(\"3) defensive\")\n","    print(\"4) random\")\n","    print(\"5) patterned\")\n","    print(\"6) mixed\")\n","    choice = input(\"Select 1-6: \").strip()\n","    modes = {'1':'human','2':'aggressive','3':'defensive','4':'random','5':'patterned','6':'mixed'}\n","    mode = modes.get(choice, 'human')\n","\n","    model = play_game(model=model, opponent_mode=mode)\n","\n","    # After game, offer to save model\n","    yn = input(\"Save trained model to disk? (y/n): \").strip().lower()\n","    if yn == 'y':\n","        meta = {'saved_at': time.time()}\n","        save_model(model, meta=meta)\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMs2ak1EmhSEMSIMQLEpMXP"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}